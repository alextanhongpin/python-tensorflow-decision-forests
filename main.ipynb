{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a095e2-0c58-4872-8da1-e950141b8bbd",
   "metadata": {},
   "source": [
    "# Tensorflow Decision Forests\n",
    "\n",
    "References\n",
    "- https://substack.com/redirect/f92a3394-4ba0-46de-850b-46fbfa07e2fd?j=eyJ1IjoiZ3o2OXoifQ.eD3drYwi8N4WQMFVjqUvXwYHqAdLUSzYowEDrQzJe4Q\n",
    "- https://www.tensorflow.org/decision_forests/tutorials/beginner_colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67bc2b51-3108-483a-96e6-518dd2695f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this to install the lib.\n",
    "# !pip install tensorflow_decision_forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9641a93e-b642-4ecb-83ac-9822fb41b230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da018ee-ac2c-4ebe-9cf0-9ffd85576d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found TensorFlow Decision Forests v1.2.0\n"
     ]
    }
   ],
   "source": [
    "# Check the version of TensorFlow Decision Forests\n",
    "print(\"Found TensorFlow Decision Forests v\" + tfdf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106f93f-02fc-49d5-bbf0-507580e7b448",
   "metadata": {},
   "source": [
    "## Training a Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be7984f5-8ce8-445d-a019-fce6b6e55132",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 15241  100 15241    0     0   6942      0  0:00:02  0:00:02 --:--:--  6968\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!curl https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins.csv -o ./data/penguins.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39083fd4-e452-4bb1-9bb3-7b2bf16350e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_csv(\"./data/penguins.csv\")\n",
    "dataset_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1248bf4a-943e-4582-80b8-85f8b1a69355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      " 7   year               344 non-null    int64  \n",
      "dtypes: float64(4), int64(1), object(3)\n",
      "memory usage: 21.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616360e-0351-469d-b985-9aef13ff9c98",
   "metadata": {},
   "source": [
    "We observe the following:\n",
    "- the dataset contains a mix of numerical and categorical features\n",
    "- there are 5 features with incomplete columns (`bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, `body_mass_g` and `sex`)\n",
    "\n",
    "\n",
    "TF-DF supports all these feature type natively, therefore there is no need for preprocessing in the form of one-hot encoding, normalization of extra `is_present` feature.\n",
    "\n",
    "However, since Keras metrics expects integers, the labels needs to be converted into integer. `pd_dataframe_to_tf_dataset` automatically converts the labels to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8007b4aa-bdfe-450f-8dec-0f97dd634485",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>344</td>\n",
       "      <td>344</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>152</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       species  island   sex\n",
       "count      344     344   333\n",
       "unique       3       3     2\n",
       "top     Adelie  Biscoe  male\n",
       "freq       152     168   168"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out info about objects.\n",
    "dataset_df.describe(include=\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7326bdfa-3e32-40ed-a9e5-dd2356470423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 examples in training, 89 examples for testing\n"
     ]
    }
   ],
   "source": [
    "# Splilt the dataset into training and testing dataset.\n",
    "\n",
    "\n",
    "def split_dataset(dataset, test_ratio=0.30):\n",
    "    \"\"\"Splits a panda dataframe in two.\"\"\"\n",
    "    test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "    return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "\n",
    "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
    "print(\n",
    "    \"{} examples in training, {} examples for testing\".format(\n",
    "        len(train_ds_pd), len(test_ds_pd)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39d929d5-f457-4728-956e-b25daee796bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = \"species\"\n",
    "\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b1e43d9-edca-4a7b-8cfb-6e97630263c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 4 thread(s) for training\n",
      "Use /var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/tmp05v8ooiu as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'island': <tf.Tensor 'data_4:0' shape=(None,) dtype=string>, 'bill_length_mm': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'bill_depth_mm': <tf.Tensor 'data:0' shape=(None,) dtype=float64>, 'flipper_length_mm': <tf.Tensor 'data_3:0' shape=(None,) dtype=float64>, 'body_mass_g': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'sex': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>, 'year': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>}\n",
      "Label: Tensor(\"data_7:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized tensor features:\n",
      " {'island': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_4:0' shape=(None,) dtype=string>), 'bill_length_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'bill_depth_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'flipper_length_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'body_mass_g': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'sex': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_5:0' shape=(None,) dtype=string>), 'year': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>)}\n",
      "Training dataset read in 0:00:06.780670. Found 255 examples.\n",
      "Training model...\n",
      "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2023-02-24T15:07:47.504686+08:00 kernel.cc:756] Start Yggdrasil model training\n",
      "[INFO 2023-02-24T15:07:47.508026+08:00 kernel.cc:757] Collect training examples\n",
      "[INFO 2023-02-24T15:07:47.508145+08:00 kernel.cc:388] Number of batches: 1\n",
      "[INFO 2023-02-24T15:07:47.50816+08:00 kernel.cc:389] Number of examples: 255\n",
      "[INFO 2023-02-24T15:07:47.508316+08:00 kernel.cc:774] Training dataset:\n",
      "Number of records: 255\n",
      "Number of columns: 8\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 5 (62.5%)\n",
      "\tCATEGORICAL: 3 (37.5%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 5 (62.5%)\n",
      "\t1: \"bill_depth_mm\" NUMERICAL num-nas:2 (0.784314%) mean:17.2593 min:13.1 max:21.5 sd:1.98563\n",
      "\t2: \"bill_length_mm\" NUMERICAL num-nas:2 (0.784314%) mean:43.7379 min:33.5 max:54.2 sd:5.2196\n",
      "\t3: \"body_mass_g\" NUMERICAL num-nas:2 (0.784314%) mean:4165.22 min:2700 max:6000 sd:772.7\n",
      "\t4: \"flipper_length_mm\" NUMERICAL num-nas:2 (0.784314%) mean:200.289 min:172 max:230 sd:13.9403\n",
      "\t7: \"year\" NUMERICAL mean:2008 min:2007 max:2009 sd:0.7995\n",
      "\n",
      "CATEGORICAL: 3 (37.5%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\t5: \"island\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"Biscoe\" 118 (46.2745%)\n",
      "\t6: \"sex\" CATEGORICAL num-nas:10 (3.92157%) has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 128 (52.2449%)\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 2023-02-24T15:07:47.509135+08:00 kernel.cc:790] Configure learner\n",
      "[INFO 2023-02-24T15:07:47.510047+08:00 kernel.cc:804] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^bill_depth_mm$\"\n",
      "features: \"^bill_length_mm$\"\n",
      "features: \"^body_mass_g$\"\n",
      "features: \"^flipper_length_mm$\"\n",
      "features: \"^island$\"\n",
      "features: \"^sex$\"\n",
      "features: \"^year$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "[INFO 2023-02-24T15:07:47.510786+08:00 kernel.cc:807] Deployment config:\n",
      "cache_path: \"/var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/tmp05v8ooiu/working_cache\"\n",
      "num_threads: 4\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 2023-02-24T15:07:47.511138+08:00 kernel.cc:868] Train model\n",
      "[INFO 2023-02-24T15:07:47.511272+08:00 random_forest.cc:415] Training random forest on 255 example(s) and 7 feature(s).\n",
      "[INFO 2023-02-24T15:07:47.512103+08:00 random_forest.cc:804] Training of tree  1/300 (tree index:3) done accuracy:0.902174 logloss:3.52601\n",
      "[INFO 2023-02-24T15:07:47.512984+08:00 random_forest.cc:804] Training of tree  11/300 (tree index:10) done accuracy:0.948617 logloss:0.642478\n",
      "[INFO 2023-02-24T15:07:47.513736+08:00 random_forest.cc:804] Training of tree  21/300 (tree index:21) done accuracy:0.968627 logloss:0.223163\n",
      "[INFO 2023-02-24T15:07:47.514495+08:00 random_forest.cc:804] Training of tree  31/300 (tree index:31) done accuracy:0.968627 logloss:0.221421\n",
      "[INFO 2023-02-24T15:07:47.515089+08:00 random_forest.cc:804] Training of tree  41/300 (tree index:40) done accuracy:0.976471 logloss:0.217554\n",
      "[INFO 2023-02-24T15:07:47.515701+08:00 random_forest.cc:804] Training of tree  51/300 (tree index:50) done accuracy:0.976471 logloss:0.212916\n",
      "[INFO 2023-02-24T15:07:47.516421+08:00 random_forest.cc:804] Training of tree  61/300 (tree index:61) done accuracy:0.976471 logloss:0.215858\n",
      "[INFO 2023-02-24T15:07:47.517452+08:00 random_forest.cc:804] Training of tree  71/300 (tree index:70) done accuracy:0.972549 logloss:0.216807\n",
      "[INFO 2023-02-24T15:07:47.51843+08:00 random_forest.cc:804] Training of tree  81/300 (tree index:79) done accuracy:0.972549 logloss:0.218132\n",
      "[INFO 2023-02-24T15:07:47.519332+08:00 random_forest.cc:804] Training of tree  92/300 (tree index:85) done accuracy:0.976471 logloss:0.216541\n",
      "[INFO 2023-02-24T15:07:47.520528+08:00 random_forest.cc:804] Training of tree  102/300 (tree index:102) done accuracy:0.980392 logloss:0.218544\n",
      "[INFO 2023-02-24T15:07:47.521828+08:00 random_forest.cc:804] Training of tree  112/300 (tree index:107) done accuracy:0.976471 logloss:0.21838\n",
      "[INFO 2023-02-24T15:07:47.52301+08:00 random_forest.cc:804] Training of tree  122/300 (tree index:120) done accuracy:0.980392 logloss:0.217533\n",
      "[INFO 2023-02-24T15:07:47.524509+08:00 random_forest.cc:804] Training of tree  132/300 (tree index:130) done accuracy:0.980392 logloss:0.218553\n",
      "[INFO 2023-02-24T15:07:47.526154+08:00 random_forest.cc:804] Training of tree  142/300 (tree index:142) done accuracy:0.980392 logloss:0.218481\n",
      "[INFO 2023-02-24T15:07:47.528437+08:00 random_forest.cc:804] Training of tree  152/300 (tree index:152) done accuracy:0.980392 logloss:0.218421\n",
      "[INFO 2023-02-24T15:07:47.529397+08:00 random_forest.cc:804] Training of tree  162/300 (tree index:161) done accuracy:0.980392 logloss:0.217474\n",
      "[INFO 2023-02-24T15:07:47.530591+08:00 random_forest.cc:804] Training of tree  172/300 (tree index:170) done accuracy:0.980392 logloss:0.217956\n",
      "[INFO 2023-02-24T15:07:47.531942+08:00 random_forest.cc:804] Training of tree  182/300 (tree index:181) done accuracy:0.980392 logloss:0.217883\n",
      "[INFO 2023-02-24T15:07:47.533407+08:00 random_forest.cc:804] Training of tree  192/300 (tree index:191) done accuracy:0.980392 logloss:0.217906\n",
      "[INFO 2023-02-24T15:07:47.534654+08:00 random_forest.cc:804] Training of tree  202/300 (tree index:200) done accuracy:0.980392 logloss:0.217994\n",
      "[INFO 2023-02-24T15:07:47.535726+08:00 random_forest.cc:804] Training of tree  212/300 (tree index:211) done accuracy:0.980392 logloss:0.218881\n",
      "[INFO 2023-02-24T15:07:47.536987+08:00 random_forest.cc:804] Training of tree  222/300 (tree index:214) done accuracy:0.980392 logloss:0.218732\n",
      "[INFO 2023-02-24T15:07:47.538212+08:00 random_forest.cc:804] Training of tree  232/300 (tree index:232) done accuracy:0.980392 logloss:0.217644\n",
      "[INFO 2023-02-24T15:07:47.539679+08:00 random_forest.cc:804] Training of tree  242/300 (tree index:240) done accuracy:0.980392 logloss:0.215806\n",
      "[INFO 2023-02-24T15:07:47.541497+08:00 random_forest.cc:804] Training of tree  252/300 (tree index:251) done accuracy:0.980392 logloss:0.215291\n",
      "[INFO 2023-02-24T15:07:47.542788+08:00 random_forest.cc:804] Training of tree  262/300 (tree index:261) done accuracy:0.980392 logloss:0.214975\n",
      "[INFO 2023-02-24T15:07:47.544032+08:00 random_forest.cc:804] Training of tree  272/300 (tree index:271) done accuracy:0.980392 logloss:0.214809\n",
      "[INFO 2023-02-24T15:07:47.545973+08:00 random_forest.cc:804] Training of tree  282/300 (tree index:281) done accuracy:0.980392 logloss:0.215196\n",
      "[INFO 2023-02-24T15:07:47.547752+08:00 random_forest.cc:804] Training of tree  292/300 (tree index:292) done accuracy:0.980392 logloss:0.216021\n",
      "[INFO 2023-02-24T15:07:47.549004+08:00 random_forest.cc:804] Training of tree  300/300 (tree index:299) done accuracy:0.980392 logloss:0.216272\n",
      "[INFO 2023-02-24T15:07:47.549862+08:00 random_forest.cc:884] Final OOB metrics: accuracy:0.980392 logloss:0.216272\n",
      "[INFO 2023-02-24T15:07:47.551138+08:00 kernel.cc:905] Export model in log directory: /var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/tmp05v8ooiu with prefix 34f26869bb7248fb\n",
      "[INFO 2023-02-24T15:07:47.565472+08:00 kernel.cc:923] Save model in resources\n",
      "[INFO 2023-02-24T15:07:47.576914+08:00 abstract_model.cc:849] Model self evaluation:\n",
      "Number of predictions (without weights): 255\n",
      "Number of predictions (with weights): 255\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.980392  CI95[W][0.959217 0.992243]\n",
      "LogLoss: : 0.216272\n",
      "ErrorRate: : 0.0196078\n",
      "\n",
      "Default Accuracy: : 0.454902\n",
      "Default LogLoss: : 1.04944\n",
      "Default ErrorRate: : 0.545098\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "   0    1   2   3\n",
      "0  0    0   0   0\n",
      "1  0  114   2   0\n",
      "2  0    1  51   0\n",
      "3  0    2   0  85\n",
      "Total: 255\n",
      "\n",
      "One vs other classes:\n",
      "\n",
      "[INFO 2023-02-24T15:07:47.612042+08:00 kernel.cc:1214] Loading model from path /var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/tmp05v8ooiu/model/ with prefix 34f26869bb7248fb\n",
      "[INFO 2023-02-24T15:07:47.630824+08:00 decision_forest.cc:661] Model loaded with 300 root(s), 4596 node(s), and 7 input feature(s).\n",
      "[INFO 2023-02-24T15:07:47.631152+08:00 abstract_model.cc:1312] Engine \"RandomForestGeneric\" built\n",
      "[INFO 2023-02-24T15:07:47.631206+08:00 kernel.cc:1046] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.282834\n",
      "Compiling model...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x12f8a1b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x12f8a1b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x12f8a1b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x139a79580>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the model.\n",
    "model_1 = tfdf.keras.RandomForestModel(verbose=2)\n",
    "\n",
    "# Train the model.\n",
    "model_1.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f84eb659-ff09-46de-917e-3de979487d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_1.compile(metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbe3cb02-b55e-4196-9cf6-c68b2ad19c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 0.9888\n",
      "\n",
      "loss: 0.0000\n",
      "accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97b71b05-f42c-4716-9164-ec031f8c77c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as call_get_leaves, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    }
   ],
   "source": [
    "model_1.save(\"./model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8b1972-27de-4a13-82fd-776d0527fb3e",
   "metadata": {},
   "source": [
    "## Plot the model\n",
    "\n",
    "Plotting a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c688d71e-542f-4022-b13e-dd56891672d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"plot.html\", \"w\") as f:\n",
    "    f.write(tfdf.model_plotter.plot_model(model_1, tree_idx=0, max_depth=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99f37058-ff03-4b24-9d87-fe8ea19389da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"random_forest_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "Type: \"RANDOM_FOREST\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (7):\n",
      "\tbill_depth_mm\n",
      "\tbill_length_mm\n",
      "\tbody_mass_g\n",
      "\tflipper_length_mm\n",
      "\tisland\n",
      "\tsex\n",
      "\tyear\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1.    \"bill_length_mm\"  0.433414 ################\n",
      "    2. \"flipper_length_mm\"  0.413256 ##############\n",
      "    3.     \"bill_depth_mm\"  0.327793 #######\n",
      "    4.            \"island\"  0.307764 ######\n",
      "    5.       \"body_mass_g\"  0.261758 ##\n",
      "    6.               \"sex\"  0.234458 \n",
      "    7.              \"year\"  0.232359 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1. \"flipper_length_mm\" 141.000000 ################\n",
      "    2.    \"bill_length_mm\" 84.000000 #########\n",
      "    3.     \"bill_depth_mm\" 67.000000 #######\n",
      "    4.            \"island\"  5.000000 \n",
      "    5.       \"body_mass_g\"  3.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.    \"bill_length_mm\" 700.000000 ################\n",
      "    2.     \"bill_depth_mm\" 455.000000 ##########\n",
      "    3. \"flipper_length_mm\" 358.000000 ########\n",
      "    4.            \"island\" 310.000000 ######\n",
      "    5.       \"body_mass_g\" 275.000000 ######\n",
      "    6.               \"sex\" 34.000000 \n",
      "    7.              \"year\" 16.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.    \"bill_length_mm\" 27376.301517 ################\n",
      "    2. \"flipper_length_mm\" 22801.028991 #############\n",
      "    3.     \"bill_depth_mm\" 13272.478499 #######\n",
      "    4.            \"island\" 10752.762287 ######\n",
      "    5.       \"body_mass_g\" 2345.932611 #\n",
      "    6.               \"sex\" 257.707337 \n",
      "    7.              \"year\" 33.064073 \n",
      "\n",
      "\n",
      "\n",
      "Winner takes all: true\n",
      "Out-of-bag evaluation: accuracy:0.980392 logloss:0.216272\n",
      "Number of trees: 300\n",
      "Total number of nodes: 4596\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 300 Average: 15.32 StdDev: 2.98512\n",
      "Min: 9 Max: 25 Ignored: 0\n",
      "----------------------------------------------\n",
      "[  9, 10)  3   1.00%   1.00%\n",
      "[ 10, 11)  0   0.00%   1.00%\n",
      "[ 11, 12) 32  10.67%  11.67% ####\n",
      "[ 12, 13)  0   0.00%  11.67%\n",
      "[ 13, 14) 75  25.00%  36.67% ##########\n",
      "[ 14, 15)  0   0.00%  36.67%\n",
      "[ 15, 16) 76  25.33%  62.00% ##########\n",
      "[ 16, 17)  0   0.00%  62.00%\n",
      "[ 17, 18) 64  21.33%  83.33% ########\n",
      "[ 18, 19)  0   0.00%  83.33%\n",
      "[ 19, 20) 28   9.33%  92.67% ####\n",
      "[ 20, 21)  0   0.00%  92.67%\n",
      "[ 21, 22) 13   4.33%  97.00% ##\n",
      "[ 22, 23)  0   0.00%  97.00%\n",
      "[ 23, 24)  8   2.67%  99.67% #\n",
      "[ 24, 25)  0   0.00%  99.67%\n",
      "[ 25, 25]  1   0.33% 100.00%\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 2448 Average: 3.38317 StdDev: 1.06077\n",
      "Min: 1 Max: 7 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 1, 2)  10   0.41%   0.41%\n",
      "[ 2, 3) 579  23.65%  24.06% ########\n",
      "[ 3, 4) 737  30.11%  54.17% ##########\n",
      "[ 4, 5) 767  31.33%  85.50% ##########\n",
      "[ 5, 6) 299  12.21%  97.71% ####\n",
      "[ 6, 7)  52   2.12%  99.84% #\n",
      "[ 7, 7]   4   0.16% 100.00%\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 2448 Average: 31.25 StdDev: 33.2288\n",
      "Min: 5 Max: 123 Ignored: 0\n",
      "----------------------------------------------\n",
      "[   5,  10) 1269  51.84%  51.84% ##########\n",
      "[  10,  16)  100   4.08%  55.92% #\n",
      "[  16,  22)   68   2.78%  58.70% #\n",
      "[  22,  28)   60   2.45%  61.15%\n",
      "[  28,  34)   74   3.02%  64.17% #\n",
      "[  34,  40)   87   3.55%  67.73% #\n",
      "[  40,  46)   89   3.64%  71.36% #\n",
      "[  46,  52)   64   2.61%  73.98% #\n",
      "[  52,  58)   41   1.67%  75.65%\n",
      "[  58,  64)   26   1.06%  76.72%\n",
      "[  64,  70)   49   2.00%  78.72%\n",
      "[  70,  76)  101   4.13%  82.84% #\n",
      "[  76,  82)   91   3.72%  86.56% #\n",
      "[  82,  88)   93   3.80%  90.36% #\n",
      "[  88,  94)   92   3.76%  94.12% #\n",
      "[  94, 100)   53   2.17%  96.28%\n",
      "[ 100, 106)   41   1.67%  97.96%\n",
      "[ 106, 112)   34   1.39%  99.35%\n",
      "[ 112, 118)   13   0.53%  99.88%\n",
      "[ 118, 123]    3   0.12% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t700 : bill_length_mm [NUMERICAL]\n",
      "\t455 : bill_depth_mm [NUMERICAL]\n",
      "\t358 : flipper_length_mm [NUMERICAL]\n",
      "\t310 : island [CATEGORICAL]\n",
      "\t275 : body_mass_g [NUMERICAL]\n",
      "\t34 : sex [CATEGORICAL]\n",
      "\t16 : year [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t141 : flipper_length_mm [NUMERICAL]\n",
      "\t84 : bill_length_mm [NUMERICAL]\n",
      "\t67 : bill_depth_mm [NUMERICAL]\n",
      "\t5 : island [CATEGORICAL]\n",
      "\t3 : body_mass_g [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t246 : bill_length_mm [NUMERICAL]\n",
      "\t217 : flipper_length_mm [NUMERICAL]\n",
      "\t206 : bill_depth_mm [NUMERICAL]\n",
      "\t151 : island [CATEGORICAL]\n",
      "\t69 : body_mass_g [NUMERICAL]\n",
      "\t1 : sex [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t431 : bill_length_mm [NUMERICAL]\n",
      "\t336 : bill_depth_mm [NUMERICAL]\n",
      "\t294 : flipper_length_mm [NUMERICAL]\n",
      "\t263 : island [CATEGORICAL]\n",
      "\t152 : body_mass_g [NUMERICAL]\n",
      "\t14 : sex [CATEGORICAL]\n",
      "\t1 : year [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t616 : bill_length_mm [NUMERICAL]\n",
      "\t423 : bill_depth_mm [NUMERICAL]\n",
      "\t332 : flipper_length_mm [NUMERICAL]\n",
      "\t303 : island [CATEGORICAL]\n",
      "\t245 : body_mass_g [NUMERICAL]\n",
      "\t28 : sex [CATEGORICAL]\n",
      "\t9 : year [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t699 : bill_length_mm [NUMERICAL]\n",
      "\t455 : bill_depth_mm [NUMERICAL]\n",
      "\t357 : flipper_length_mm [NUMERICAL]\n",
      "\t310 : island [CATEGORICAL]\n",
      "\t275 : body_mass_g [NUMERICAL]\n",
      "\t34 : sex [CATEGORICAL]\n",
      "\t16 : year [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t1804 : HigherCondition\n",
      "\t344 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t295 : HigherCondition\n",
      "\t5 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t738 : HigherCondition\n",
      "\t152 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t1214 : HigherCondition\n",
      "\t277 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t1625 : HigherCondition\n",
      "\t331 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t1802 : HigherCondition\n",
      "\t344 : ContainsBitmapCondition\n",
      "Node format: NOT_SET\n",
      "\n",
      "Training OOB:\n",
      "\ttrees: 1, Out-of-bag evaluation: accuracy:0.902174 logloss:3.52601\n",
      "\ttrees: 11, Out-of-bag evaluation: accuracy:0.948617 logloss:0.642478\n",
      "\ttrees: 21, Out-of-bag evaluation: accuracy:0.968627 logloss:0.223163\n",
      "\ttrees: 31, Out-of-bag evaluation: accuracy:0.968627 logloss:0.221421\n",
      "\ttrees: 41, Out-of-bag evaluation: accuracy:0.976471 logloss:0.217554\n",
      "\ttrees: 51, Out-of-bag evaluation: accuracy:0.976471 logloss:0.212916\n",
      "\ttrees: 61, Out-of-bag evaluation: accuracy:0.976471 logloss:0.215858\n",
      "\ttrees: 71, Out-of-bag evaluation: accuracy:0.972549 logloss:0.216807\n",
      "\ttrees: 81, Out-of-bag evaluation: accuracy:0.972549 logloss:0.218132\n",
      "\ttrees: 92, Out-of-bag evaluation: accuracy:0.976471 logloss:0.216541\n",
      "\ttrees: 102, Out-of-bag evaluation: accuracy:0.980392 logloss:0.218544\n",
      "\ttrees: 112, Out-of-bag evaluation: accuracy:0.976471 logloss:0.21838\n",
      "\ttrees: 122, Out-of-bag evaluation: accuracy:0.980392 logloss:0.217533\n",
      "\ttrees: 132, Out-of-bag evaluation: accuracy:0.980392 logloss:0.218553\n",
      "\ttrees: 142, Out-of-bag evaluation: accuracy:0.980392 logloss:0.218481\n",
      "\ttrees: 152, Out-of-bag evaluation: accuracy:0.980392 logloss:0.218421\n",
      "\ttrees: 162, Out-of-bag evaluation: accuracy:0.980392 logloss:0.217474\n",
      "\ttrees: 172, Out-of-bag evaluation: accuracy:0.980392 logloss:0.217956\n",
      "\ttrees: 182, Out-of-bag evaluation: accuracy:0.980392 logloss:0.217883\n",
      "\ttrees: 192, Out-of-bag evaluation: accuracy:0.980392 logloss:0.217906\n",
      "\ttrees: 202, Out-of-bag evaluation: accuracy:0.980392 logloss:0.217994\n",
      "\ttrees: 212, Out-of-bag evaluation: accuracy:0.980392 logloss:0.218881\n",
      "\ttrees: 222, Out-of-bag evaluation: accuracy:0.980392 logloss:0.218732\n",
      "\ttrees: 232, Out-of-bag evaluation: accuracy:0.980392 logloss:0.217644\n",
      "\ttrees: 242, Out-of-bag evaluation: accuracy:0.980392 logloss:0.215806\n",
      "\ttrees: 252, Out-of-bag evaluation: accuracy:0.980392 logloss:0.215291\n",
      "\ttrees: 262, Out-of-bag evaluation: accuracy:0.980392 logloss:0.214975\n",
      "\ttrees: 272, Out-of-bag evaluation: accuracy:0.980392 logloss:0.214809\n",
      "\ttrees: 282, Out-of-bag evaluation: accuracy:0.980392 logloss:0.215196\n",
      "\ttrees: 292, Out-of-bag evaluation: accuracy:0.980392 logloss:0.216021\n",
      "\ttrees: 300, Out-of-bag evaluation: accuracy:0.980392 logloss:0.216272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c9e8dd6-1ba8-4e1b-bfa7-e4d399f90ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"bill_depth_mm\" (1; #1),\n",
       " \"bill_length_mm\" (1; #2),\n",
       " \"body_mass_g\" (1; #3),\n",
       " \"flipper_length_mm\" (1; #4),\n",
       " \"island\" (4; #5),\n",
       " \"sex\" (4; #6),\n",
       " \"year\" (1; #7)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The input features.\n",
    "model_1.make_inspector().features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b55892f-1d23-48ed-9fa1-4f66d69fccc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NUM_NODES': [(\"bill_length_mm\" (1; #2), 700.0),\n",
       "  (\"bill_depth_mm\" (1; #1), 455.0),\n",
       "  (\"flipper_length_mm\" (1; #4), 358.0),\n",
       "  (\"island\" (4; #5), 310.0),\n",
       "  (\"body_mass_g\" (1; #3), 275.0),\n",
       "  (\"sex\" (4; #6), 34.0),\n",
       "  (\"year\" (1; #7), 16.0)],\n",
       " 'NUM_AS_ROOT': [(\"flipper_length_mm\" (1; #4), 141.0),\n",
       "  (\"bill_length_mm\" (1; #2), 84.0),\n",
       "  (\"bill_depth_mm\" (1; #1), 67.0),\n",
       "  (\"island\" (4; #5), 5.0),\n",
       "  (\"body_mass_g\" (1; #3), 3.0)],\n",
       " 'INV_MEAN_MIN_DEPTH': [(\"bill_length_mm\" (1; #2), 0.43341353255698634),\n",
       "  (\"flipper_length_mm\" (1; #4), 0.41325608613221976),\n",
       "  (\"bill_depth_mm\" (1; #1), 0.3277930681305042),\n",
       "  (\"island\" (4; #5), 0.3077635174943425),\n",
       "  (\"body_mass_g\" (1; #3), 0.261758426124752),\n",
       "  (\"sex\" (4; #6), 0.23445836152941973),\n",
       "  (\"year\" (1; #7), 0.2323586486821575)],\n",
       " 'SUM_SCORE': [(\"bill_length_mm\" (1; #2), 27376.301516973414),\n",
       "  (\"flipper_length_mm\" (1; #4), 22801.028990549967),\n",
       "  (\"bill_depth_mm\" (1; #1), 13272.478498751298),\n",
       "  (\"island\" (4; #5), 10752.762287171558),\n",
       "  (\"body_mass_g\" (1; #3), 2345.9326108340174),\n",
       "  (\"sex\" (4; #6), 257.70733718946576),\n",
       "  (\"year\" (1; #7), 33.06407251954079)]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The feature importances.\n",
    "model_1.make_inspector().variable_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a9d1042-e166-4e3d-beba-1759157d9f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(num_examples=255, accuracy=0.9803921568627451, loss=0.21627223135574775, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.make_inspector().evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "613246d9-1ceb-4324-b49e-e64514a8ecf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Logloss (out-of-bag)')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = model_1.make_inspector().training_logs()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Accuracy (out-of-bag)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Logloss (out-of-bag)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f421026-de2f-4356-8e90-af12717774d6",
   "metadata": {},
   "source": [
    "## Re-train the model with a different learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d168a44-ea7c-47f1-8d88-98d08a97fcd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensorflow_decision_forests.keras.RandomForestModel,\n",
       " tensorflow_decision_forests.keras.GradientBoostedTreesModel,\n",
       " tensorflow_decision_forests.keras.CartModel,\n",
       " tensorflow_decision_forests.keras.DistributedGradientBoostedTreesModel]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf.keras.get_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7a07711-33cf-41f6-87e6-1b1eb13b757a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomForestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Random Forest learning algorithm.\n",
       "\n",
       "A Random Forest (https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)\n",
       "is a collection of deep CART decision trees trained independently and without\n",
       "pruning. Each tree is trained on a random subset of the original training \n",
       "dataset (sampled with replacement).\n",
       "\n",
       "The algorithm is unique in that it is robust to overfitting, even in extreme\n",
       "cases e.g. when there are more features than training examples.\n",
       "\n",
       "It is probably the most well-known of the Decision Forest training\n",
       "algorithms.\n",
       "\n",
       "Usage example:\n",
       "\n",
       "```python\n",
       "import tensorflow_decision_forests as tfdf\n",
       "import pandas as pd\n",
       "\n",
       "dataset = pd.read_csv(\"project/dataset.csv\")\n",
       "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(dataset, label=\"my_label\")\n",
       "\n",
       "model = tfdf.keras.RandomForestModel()\n",
       "model.fit(tf_dataset)\n",
       "\n",
       "print(model.summary())\n",
       "```\n",
       "\n",
       "Hyper-parameter tuning:\n",
       "\n",
       "```python\n",
       "import tensorflow_decision_forests as tfdf\n",
       "import pandas as pd\n",
       "\n",
       "dataset = pd.read_csv(\"project/dataset.csv\")\n",
       "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(dataset, label=\"my_label\")\n",
       "\n",
       "tuner = tfdf.tuner.RandomSearch(num_trials=20)\n",
       "\n",
       "# Hyper-parameters to optimize.\n",
       "tuner.discret(\"max_depth\", [4, 5, 6, 7])\n",
       "\n",
       "model = tfdf.keras.RandomForestModel(tuner=tuner)\n",
       "model.fit(tf_dataset)\n",
       "\n",
       "print(model.summary())\n",
       "```\n",
       "\n",
       "\n",
       "Attributes:\n",
       "  task: Task to solve (e.g. Task.CLASSIFICATION, Task.REGRESSION,\n",
       "    Task.RANKING, Task.CATEGORICAL_UPLIFT, Task.NUMERICAL_UPLIFT).\n",
       "  features: Specify the list and semantic of the input features of the model.\n",
       "    If not specified, all the available features will be used. If specified\n",
       "    and if `exclude_non_specified_features=True`, only the features in\n",
       "    `features` will be used by the model. If \"preprocessing\" is used,\n",
       "    `features` corresponds to the output of the preprocessing. In this case,\n",
       "    it is recommended for the preprocessing to return a dictionary of tensors.\n",
       "  exclude_non_specified_features: If true, only use the features specified in\n",
       "    `features`.\n",
       "  preprocessing: Functional keras model or @tf.function to apply on the input\n",
       "    feature before the model to train. This preprocessing model can consume\n",
       "    and return tensors, list of tensors or dictionary of tensors. If\n",
       "    specified, the model only \"sees\" the output of the preprocessing (and not\n",
       "    the raw input). Can be used to prepare the features or to stack multiple\n",
       "    models on top of each other. Unlike preprocessing done in the tf.dataset,\n",
       "    the operation in \"preprocessing\" are serialized with the model.\n",
       "  postprocessing: Like \"preprocessing\" but applied on the model output.\n",
       "  ranking_group: Only for `task=Task.RANKING`. Name of a tf.string feature that\n",
       "    identifies queries in a query/document ranking task. The ranking group\n",
       "    is not added automatically for the set of features if\n",
       "    `exclude_non_specified_features=false`.\n",
       "  uplift_treatment: Only for task=Task.CATEGORICAL_UPLIFT or\n",
       "    task=Task.NUMERICAL_UPLIFT. Name of an integer feature that identifies the\n",
       "    treatment in an uplift problem. The value 0 is reserved for the control\n",
       "    treatment.\n",
       "  temp_directory: Temporary directory used to store the model Assets after the\n",
       "    training, and possibly as a work directory during the training. This\n",
       "    temporary directory is necessary for the model to be exported after\n",
       "    training e.g. `model.save(path)`. If not specified, `temp_directory` is\n",
       "    set to a temporary directory using `tempfile.TemporaryDirectory`. This\n",
       "    directory is deleted when the model python object is garbage-collected.\n",
       "  verbose: Verbosity mode. 0 = silent, 1 = small details, 2 = full details.\n",
       "  hyperparameter_template: Override the default value of the hyper-parameters.\n",
       "    If None (default) the default parameters of the library are used. If set,\n",
       "    `default_hyperparameter_template` refers to one of the following\n",
       "    preconfigured hyper-parameter sets. Those sets outperforms the default\n",
       "    hyper-parameters (either generally or in specific scenarios).\n",
       "    You can omit the version (e.g. remove \"@v5\") to use the last version of\n",
       "    the template. In this case, the hyper-parameter can change in between\n",
       "    releases (not recommended for training in production).\n",
       "    - better_default@v1: A configuration that is generally better than the\n",
       "      default parameters without being more expensive. The parameters are:\n",
       "      winner_take_all=True.\n",
       "    - benchmark_rank1@v1: Top ranking hyper-parameters on our benchmark\n",
       "      slightly modified to run in reasonable time. The parameters are:\n",
       "      winner_take_all=True, categorical_algorithm=\"RANDOM\",\n",
       "      split_axis=\"SPARSE_OBLIQUE\", sparse_oblique_normalization=\"MIN_MAX\",\n",
       "      sparse_oblique_num_projections_exponent=1.0.\n",
       "\n",
       "  advanced_arguments: Advanced control of the model that most users won't need\n",
       "    to use. See `AdvancedArguments` for details.\n",
       "  num_threads: Number of threads used to train the model. Different learning\n",
       "    algorithms use multi-threading differently and with different degree of\n",
       "    efficiency. If `None`, `num_threads` will be automatically set to the\n",
       "    number of processors (up to a maximum of 32; or set to 6 if the number of\n",
       "    processors is not available).\n",
       "    Making `num_threads` significantly larger than the number of processors\n",
       "    can slow-down the training speed. The default value logic might change in\n",
       "    the future.\n",
       "  name: The name of the model.\n",
       "  max_vocab_count: Default maximum size of the vocabulary for CATEGORICAL and\n",
       "    CATEGORICAL_SET features stored as strings. If more unique values exist,\n",
       "    only the most frequent values are kept, and the remaining values are\n",
       "    considered as out-of-vocabulary. The value `max_vocab_count` defined in a\n",
       "    `FeatureUsage` (if any) takes precedence.\n",
       "  try_resume_training: If true, the model training resumes from the checkpoint\n",
       "    stored in the `temp_directory` directory. If `temp_directory` does not\n",
       "    contain any model checkpoint, the training start from the beginning.\n",
       "    Resuming training is useful in the following situations: (1) The training\n",
       "      was interrupted by the user (e.g. ctrl+c or \"stop\" button in a\n",
       "      notebook). (2) the training job was interrupted (e.g. rescheduling), ond\n",
       "      (3) the hyper-parameter of the model were changed such that an initially\n",
       "      completed training is now incomplete (e.g. increasing the number of\n",
       "      trees).\n",
       "    Note: Training can only be resumed if the training datasets is exactly the\n",
       "      same (i.e. no reshuffle in the tf.data.Dataset).\n",
       "  check_dataset: If set to true, test if the dataset is well configured for\n",
       "    the training: (1) Check if the dataset does contains any `repeat`\n",
       "      operations, (2) Check if the dataset does contain a `batch` operation,\n",
       "      (3) Check if the dataset has a large enough batch size (min 100 if the\n",
       "      dataset contains more than 1k examples or if the number of examples is\n",
       "      not available) If set to false, do not run any test.\n",
       "  tuner: If set, automatically optimize the hyperparameters of the model using\n",
       "    this tuner. If the model is trained with distribution (i.e. the model\n",
       "    definition is wrapper in a TF Distribution strategy, the tuning is\n",
       "    distributed.\n",
       "  discretize_numerical_features: If true, discretize all the numerical\n",
       "    features before training. Discretized numerical features are faster to\n",
       "    train with, but they can have a negative impact on the model quality.\n",
       "    Using discretize_numerical_features=True is equivalent as setting the\n",
       "    feature semantic DISCRETIZED_NUMERICAL in the `feature` argument. See the\n",
       "    definition of DISCRETIZED_NUMERICAL for more details.\n",
       "  num_discretize_numerical_bins: Number of bins used when disretizing\n",
       "    numerical features. The value `num_discretized_numerical_bins` defined in\n",
       "    a `FeatureUsage` (if any) takes precedence.\n",
       "  multitask: If set, train a multi-task model, that is a model with multiple\n",
       "    outputs trained to predict different labels. If set, the tf.dataset label\n",
       "    (i.e. the second selement of the dataset) should be a dictionary of\n",
       "    label_key:label_values. Only one of `multitask` and `task` can be set.\n",
       "  adapt_bootstrap_size_ratio_for_maximum_training_duration: Control how the\n",
       "    maximum training duration (if set) is applied. If false, the training\n",
       "    stop when the time is used. If true, adapts the size of the sampled\n",
       "    dataset used to train each tree such that `num_trees` will train within\n",
       "    `maximum_training_duration`. Has no effect if there is no maximum\n",
       "    training duration specified. Default: False.\n",
       "  allow_na_conditions: If true, the tree training evaluates conditions of the\n",
       "    type `X is NA` i.e. `X is missing`. Default: False.\n",
       "  bootstrap_size_ratio: Number of examples used to train each trees;\n",
       "    expressed as a ratio of the training dataset size. Default: 1.0.\n",
       "  bootstrap_training_dataset: If true (default), each tree is trained on a\n",
       "    separate dataset sampled with replacement from the original dataset. If\n",
       "    false, all the trees are trained on the entire same dataset. If\n",
       "    bootstrap_training_dataset:false, OOB metrics are not available.\n",
       "    bootstrap_training_dataset=false is used in \"Extremely randomized trees\"\n",
       "    (https://link.springer.com/content/pdf/10.1007%2Fs10994-006-6226-1.pdf).\n",
       "    Default: True.\n",
       "  categorical_algorithm: How to learn splits on categorical attributes.\n",
       "    - `CART`: CART algorithm. Find categorical splits of the form \"value \\\\in\n",
       "      mask\". The solution is exact for binary classification, regression and\n",
       "      ranking. It is approximated for multi-class classification. This is a\n",
       "      good first algorithm to use. In case of overfitting (very small\n",
       "      dataset, large dictionary), the \"random\" algorithm is a good\n",
       "      alternative.\n",
       "    - `ONE_HOT`: One-hot encoding. Find the optimal categorical split of the\n",
       "      form \"attribute == param\". This method is similar (but more efficient)\n",
       "      than converting converting each possible categorical value into a\n",
       "      boolean feature. This method is available for comparison purpose and\n",
       "      generally performs worse than other alternatives.\n",
       "    - `RANDOM`: Best splits among a set of random candidate. Find the a\n",
       "      categorical split of the form \"value \\\\in mask\" using a random search.\n",
       "      This solution can be seen as an approximation of the CART algorithm.\n",
       "      This method is a strong alternative to CART. This algorithm is inspired\n",
       "      from section \"5.1 Categorical Variables\" of \"Random Forest\", 2001.\n",
       "      Default: \"CART\".\n",
       "  categorical_set_split_greedy_sampling: For categorical set splits e.g.\n",
       "    texts. Probability for a categorical value to be a candidate for the\n",
       "    positive set. The sampling is applied once per node (i.e. not at every\n",
       "    step of the greedy optimization). Default: 0.1.\n",
       "  categorical_set_split_max_num_items: For categorical set splits e.g. texts.\n",
       "    Maximum number of items (prior to the sampling). If more items are\n",
       "    available, the least frequent items are ignored. Changing this value is\n",
       "    similar to change the \"max_vocab_count\" before loading the dataset, with\n",
       "    the following exception: With `max_vocab_count`, all the remaining items\n",
       "    are grouped in a special Out-of-vocabulary item. With `max_num_items`,\n",
       "    this is not the case. Default: -1.\n",
       "  categorical_set_split_min_item_frequency: For categorical set splits e.g.\n",
       "    texts. Minimum number of occurrences of an item to be considered.\n",
       "    Default: 1.\n",
       "  compute_oob_performances: If true, compute the Out-of-bag evaluation (then\n",
       "    available in the summary and model inspector). This evaluation is a cheap\n",
       "    alternative to cross-validation evaluation. Default: True.\n",
       "  compute_oob_variable_importances: If true, compute the Out-of-bag feature\n",
       "    importance (then available in the summary and model inspector). Note that\n",
       "    the OOB feature importance can be expensive to compute. Default: False.\n",
       "  growing_strategy: How to grow the tree.\n",
       "    - `LOCAL`: Each node is split independently of the other nodes. In other\n",
       "      words, as long as a node satisfy the splits \"constraints (e.g. maximum\n",
       "      depth, minimum number of observations), the node will be split. This is\n",
       "      the \"classical\" way to grow decision trees.\n",
       "    - `BEST_FIRST_GLOBAL`: The node with the best loss reduction among all\n",
       "      the nodes of the tree is selected for splitting. This method is also\n",
       "      called \"best first\" or \"leaf-wise growth\". See \"Best-first decision\n",
       "      tree learning\", Shi and \"Additive logistic regression : A statistical\n",
       "      view of boosting\", Friedman for more details. Default: \"LOCAL\".\n",
       "  honest: In honest trees, different training examples are used to infer the\n",
       "    structure and the leaf values. This regularization technique trades\n",
       "    examples for bias estimates. It might increase or reduce the quality of\n",
       "    the model. See \"Generalized Random Forests\", Athey et al. In this paper,\n",
       "    Honest trees are trained with the Random Forest algorithm with a sampling\n",
       "    without replacement. Default: False.\n",
       "  honest_fixed_separation: For honest trees only i.e. honest=true. If true, a\n",
       "    new random separation is generated for each tree. If false, the same\n",
       "    separation is used for all the trees (e.g., in Gradient Boosted Trees\n",
       "    containing multiple trees). Default: False.\n",
       "  honest_ratio_leaf_examples: For honest trees only i.e. honest=true. Ratio\n",
       "    of examples used to set the leaf values. Default: 0.5.\n",
       "  in_split_min_examples_check: Whether to check the `min_examples` constraint\n",
       "    in the split search (i.e. splits leading to one child having less than\n",
       "    `min_examples` examples are considered invalid) or before the split\n",
       "    search (i.e. a node can be derived only if it contains more than\n",
       "    `min_examples` examples). If false, there can be nodes with less than\n",
       "    `min_examples` training examples. Default: True.\n",
       "  keep_non_leaf_label_distribution: Whether to keep the node value (i.e. the\n",
       "    distribution of the labels of the training examples) of non-leaf nodes.\n",
       "    This information is not used during serving, however it can be used for\n",
       "    model interpretation as well as hyper parameter tuning. This can take\n",
       "    lots of space, sometimes accounting for half of the model size. Default:\n",
       "    True.\n",
       "  max_depth: Maximum depth of the tree. `max_depth=1` means that all trees\n",
       "    will be roots. Negative values are ignored. Default: 16.\n",
       "  max_num_nodes: Maximum number of nodes in the tree. Set to -1 to disable\n",
       "    this limit. Only available for `growing_strategy=BEST_FIRST_GLOBAL`.\n",
       "    Default: None.\n",
       "  maximum_model_size_in_memory_in_bytes: Limit the size of the model when\n",
       "    stored in ram. Different algorithms can enforce this limit differently.\n",
       "    Note that when models are compiled into an inference, the size of the\n",
       "    inference engine is generally much smaller than the original model.\n",
       "    Default: -1.0.\n",
       "  maximum_training_duration_seconds: Maximum training duration of the model\n",
       "    expressed in seconds. Each learning algorithm is free to use this\n",
       "    parameter at it sees fit. Enabling maximum training duration makes the\n",
       "    model training non-deterministic. Default: -1.0.\n",
       "  min_examples: Minimum number of examples in a node. Default: 5.\n",
       "  missing_value_policy: Method used to handle missing attribute values.\n",
       "    - `GLOBAL_IMPUTATION`: Missing attribute values are imputed, with the\n",
       "      mean (in case of numerical attribute) or the most-frequent-item (in\n",
       "      case of categorical attribute) computed on the entire dataset (i.e. the\n",
       "      information contained in the data spec).\n",
       "    - `LOCAL_IMPUTATION`: Missing attribute values are imputed with the mean\n",
       "      (numerical attribute) or most-frequent-item (in the case of categorical\n",
       "      attribute) evaluated on the training examples in the current node.\n",
       "    - `RANDOM_LOCAL_IMPUTATION`: Missing attribute values are imputed from\n",
       "      randomly sampled values from the training examples in the current node.\n",
       "      This method was proposed by Clinic et al. in \"Random Survival Forests\"\n",
       "      (https://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908043).\n",
       "      Default: \"GLOBAL_IMPUTATION\".\n",
       "  num_candidate_attributes: Number of unique valid attributes tested for each\n",
       "    node. An attribute is valid if it has at least a valid split. If\n",
       "    `num_candidate_attributes=0`, the value is set to the classical default\n",
       "    value for Random Forest: `sqrt(number of input attributes)` in case of\n",
       "    classification and `number_of_input_attributes / 3` in case of\n",
       "    regression. If `num_candidate_attributes=-1`, all the attributes are\n",
       "    tested. Default: 0.\n",
       "  num_candidate_attributes_ratio: Ratio of attributes tested at each node. If\n",
       "    set, it is equivalent to `num_candidate_attributes =\n",
       "    number_of_input_features x num_candidate_attributes_ratio`. The possible\n",
       "    values are between ]0, and 1] as well as -1. If not set or equal to -1,\n",
       "    the `num_candidate_attributes` is used. Default: -1.0.\n",
       "  num_oob_variable_importances_permutations: Number of time the dataset is\n",
       "    re-shuffled to compute the permutation variable importances. Increasing\n",
       "    this value increase the training time (if\n",
       "    \"compute_oob_variable_importances:true\") as well as the stability of the\n",
       "    oob variable importance metrics. Default: 1.\n",
       "  num_trees: Number of individual decision trees. Increasing the number of\n",
       "    trees can increase the quality of the model at the expense of size,\n",
       "    training speed, and inference latency. Default: 300.\n",
       "  pure_serving_model: Clear the model from any information that is not\n",
       "    required for model serving. This includes debugging, model interpretation\n",
       "    and other meta-data. The size of the serialized model can be reduced\n",
       "    significatively (50% model size reduction is common). This parameter has\n",
       "    no impact on the quality, serving speed or RAM usage of model serving.\n",
       "    Default: False.\n",
       "  random_seed: Random seed for the training of the model. Learners are\n",
       "    expected to be deterministic by the random seed. Default: 123456.\n",
       "  sampling_with_replacement: If true, the training examples are sampled with\n",
       "    replacement. If false, the training samples are sampled without\n",
       "    replacement. Only used when \"bootstrap_training_dataset=true\". If false\n",
       "    (sampling without replacement) and if \"bootstrap_size_ratio=1\" (default),\n",
       "    all the examples are used to train all the trees (you probably do not\n",
       "    want that). Default: True.\n",
       "  sorting_strategy: How are sorted the numerical features in order to find\n",
       "    the splits\n",
       "    - PRESORT: The features are pre-sorted at the start of the training. This\n",
       "      solution is faster but consumes much more memory than IN_NODE.\n",
       "    - IN_NODE: The features are sorted just before being used in the node.\n",
       "      This solution is slow but consumes little amount of memory.\n",
       "    . Default: \"PRESORT\".\n",
       "  sparse_oblique_normalization: For sparse oblique splits i.e.\n",
       "    `split_axis=SPARSE_OBLIQUE`. Normalization applied on the features,\n",
       "    before applying the sparse oblique projections.\n",
       "    - `NONE`: No normalization.\n",
       "    - `STANDARD_DEVIATION`: Normalize the feature by the estimated standard\n",
       "      deviation on the entire train dataset. Also known as Z-Score\n",
       "      normalization.\n",
       "    - `MIN_MAX`: Normalize the feature by the range (i.e. max-min) estimated\n",
       "      on the entire train dataset. Default: None.\n",
       "  sparse_oblique_num_projections_exponent: For sparse oblique splits i.e.\n",
       "    `split_axis=SPARSE_OBLIQUE`. Controls of the number of random projections\n",
       "    to test at each node as `num_features^num_projections_exponent`. Default:\n",
       "    None.\n",
       "  sparse_oblique_projection_density_factor: For sparse oblique splits i.e.\n",
       "    `split_axis=SPARSE_OBLIQUE`. Controls of the number of random projections\n",
       "    to test at each node as `num_features^num_projections_exponent`. Default:\n",
       "    None.\n",
       "  sparse_oblique_weights: For sparse oblique splits i.e.\n",
       "    `split_axis=SPARSE_OBLIQUE`. Possible values:\n",
       "    - `BINARY`: The oblique weights are sampled in {-1,1} (default).\n",
       "    - `CONTINUOUS`: The oblique weights are be sampled in [-1,1]. Default:\n",
       "      None.\n",
       "  split_axis: What structure of split to consider for numerical features.\n",
       "    - `AXIS_ALIGNED`: Axis aligned splits (i.e. one condition at a time).\n",
       "      This is the \"classical\" way to train a tree. Default value.\n",
       "    - `SPARSE_OBLIQUE`: Sparse oblique splits (i.e. splits one a small number\n",
       "      of features) from \"Sparse Projection Oblique Random Forests\", Tomita et\n",
       "      al., 2020. Default: \"AXIS_ALIGNED\".\n",
       "  uplift_min_examples_in_treatment: For uplift models only. Minimum number of\n",
       "    examples per treatment in a node. Default: 5.\n",
       "  uplift_split_score: For uplift models only. Splitter score i.e. score\n",
       "    optimized by the splitters. The scores are introduced in \"Decision trees\n",
       "    for uplift modeling with single and multiple treatments\", Rzepakowski et\n",
       "    al. Notation: `p` probability / average value of the positive outcome,\n",
       "    `q` probability / average value in the control group.\n",
       "    - `KULLBACK_LEIBLER` or `KL`: - p log (p/q)\n",
       "    - `EUCLIDEAN_DISTANCE` or `ED`: (p-q)^2\n",
       "    - `CHI_SQUARED` or `CS`: (p-q)^2/q\n",
       "      Default: \"KULLBACK_LEIBLER\".\n",
       "  winner_take_all: Control how classification trees vote. If true, each tree\n",
       "    votes for one class. If false, each tree vote for a distribution of\n",
       "    classes. winner_take_all_inference=false is often preferable. Default:\n",
       "    True.\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.9/site-packages/tensorflow_decision_forests/keras/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfdf.keras.RandomForestModel?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5db29c-9d6e-4ee2-aabb-54043be6838b",
   "metadata": {},
   "source": [
    "## Using a subset of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26b62ba7-c624-4609-8093-8f6ca709dbe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/tmpq48kyasf as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.633888. Found 255 examples.\n",
      "Reading validation dataset...\n",
      "Num validation examples: tf.Tensor(89, shape=(), dtype=int32)\n",
      "Validation dataset read in 0:00:00.392211. Found 89 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.164595\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 15:23:17.330627: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1790] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2023-02-24 15:23:17.330686: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1800] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2023-02-24 15:23:17.330697: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1814] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 2023-02-24T15:23:17.460049+08:00 kernel.cc:1214] Loading model from path /var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/tmpq48kyasf/model/ with prefix 03bccd2048b14769\n",
      "[INFO 2023-02-24T15:23:17.473314+08:00 decision_forest.cc:661] Model loaded with 111 root(s), 3369 node(s), and 2 input feature(s).\n",
      "[INFO 2023-02-24T15:23:17.473367+08:00 abstract_model.cc:1312] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 2023-02-24T15:23:17.473394+08:00 kernel.cc:1046] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0000e+00 - accuracy: 0.9438\n",
      "{'loss': 0.0, 'accuracy': 0.9438202381134033}\n"
     ]
    }
   ],
   "source": [
    "feature_1 = tfdf.keras.FeatureUsage(name=\"bill_length_mm\")\n",
    "feature_2 = tfdf.keras.FeatureUsage(name=\"island\")\n",
    "\n",
    "all_features = [feature_1, feature_2]\n",
    "\n",
    "# NOTE: This model is only trained with two features, it will not be as good as the one trained with all features.\n",
    "model_2 = tfdf.keras.GradientBoostedTreesModel(\n",
    "    features=all_features, exclude_non_specified_features=True\n",
    ")\n",
    "\n",
    "model_2.compile(metrics=[\"accuracy\"])\n",
    "model_2.fit(train_ds, validation_data=test_ds)\n",
    "print(model_2.evaluate(test_ds, return_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac028cd-8828-48a4-8182-9256fc625bc7",
   "metadata": {},
   "source": [
    "## Specifying Semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ebd7011-6fba-45fd-bd98-71e7d512b8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/tmpi_j53koi as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.534937. Found 255 examples.\n",
      "Reading validation dataset...\n",
      "Num validation examples: tf.Tensor(89, shape=(), dtype=int32)\n",
      "Validation dataset read in 0:00:00.288541. Found 89 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.144988\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 15:24:40.107312: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1790] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2023-02-24 15:24:40.107336: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1800] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2023-02-24 15:24:40.107344: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1814] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 2023-02-24T15:24:40.242853+08:00 kernel.cc:1214] Loading model from path /var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/tmpi_j53koi/model/ with prefix 8832e6c7a0964f10\n",
      "[INFO 2023-02-24T15:24:40.247411+08:00 decision_forest.cc:661] Model loaded with 39 root(s), 1299 node(s), and 3 input feature(s).\n",
      "[INFO 2023-02-24T15:24:40.247467+08:00 abstract_model.cc:1312] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 2023-02-24T15:24:40.247494+08:00 kernel.cc:1046] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16bdd1760>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_1 = tfdf.keras.FeatureUsage(\n",
    "    name=\"year\", semantic=tfdf.keras.FeatureSemantic.CATEGORICAL\n",
    ")\n",
    "feature_2 = tfdf.keras.FeatureUsage(name=\"bill_length_mm\")\n",
    "feature_3 = tfdf.keras.FeatureUsage(name=\"sex\")\n",
    "all_features = [feature_1, feature_2, feature_3]\n",
    "\n",
    "model_3 = tfdf.keras.GradientBoostedTreesModel(\n",
    "    features=all_features, exclude_non_specified_features=True\n",
    ")\n",
    "model_3.compile(metrics=[\"accuracy\"])\n",
    "\n",
    "model_3.fit(train_ds, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e99b579-03cf-44a2-bb9c-78704ae4c376",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HyperParameterTemplate(name='better_default', version=1, parameters={'growing_strategy': 'BEST_FIRST_GLOBAL'}, description='A configuration that is generally better than the default parameters without being more expensive.'), HyperParameterTemplate(name='benchmark_rank1', version=1, parameters={'growing_strategy': 'BEST_FIRST_GLOBAL', 'categorical_algorithm': 'RANDOM', 'split_axis': 'SPARSE_OBLIQUE', 'sparse_oblique_normalization': 'MIN_MAX', 'sparse_oblique_num_projections_exponent': 1.0}, description='Top ranking hyper-parameters on our benchmark slightly modified to run in reasonable time.')]\n"
     ]
    }
   ],
   "source": [
    "# The hyper-parameter templates of the Gradient Boosted Tree model.\n",
    "print(tfdf.keras.GradientBoostedTreesModel.predefined_hyperparameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
